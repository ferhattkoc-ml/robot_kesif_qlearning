# ğŸ¤– Q-Learning ile Robot KeÅŸfi (Gridworld Navigation)

Bu proje, 5x5 boyutunda bir Ä±zgara (grid) ortamÄ±nda bulunan bir robotun, engellere Ã§arpmadan baÅŸlangÄ±Ã§ noktasÄ±ndan hedefe ulaÅŸmayÄ± kendi kendine Ã¶ÄŸrendiÄŸi bir PekiÅŸtirmeli Ã–ÄŸrenme (Reinforcement Learning) uygulamasÄ±dÄ±r. Ajan, ortamÄ± keÅŸfetmek ve en ideal yolu bulmak iÃ§in **Q-Learning** algoritmasÄ±nÄ± kullanmaktadÄ±r.

## ğŸ“Œ Proje DetaylarÄ± ve Ortam (Environment)

* **Durum UzayÄ± (State Space):** 5x5 Grid (Toplam 25 durum)
* **Eylem UzayÄ± (Action Space):** 4 (YukarÄ±, AÅŸaÄŸÄ±, SaÄŸa, Sola)
* **BaÅŸlangÄ±Ã§ NoktasÄ±:** `(0, 0)`
* **Hedef NoktasÄ±:** `(4, 4)`
* **Engeller:** `(0,1), (1,3), (3,1), (3,3), (4,1)`

### ğŸ† Ã–dÃ¼l MekanizmasÄ± (Reward System)
AjanÄ±n Ã¶ÄŸrenme sÃ¼recini yÃ¶nlendiren Ã¶dÃ¼l sistemi ÅŸu ÅŸekildedir:
* **Hedefe UlaÅŸma:** `+10` puan
* **Engele Ã‡arpma:** `-3` puan
* **Standart AdÄ±m:** `-0.1` puan

## ğŸ§  KullanÄ±lan Algoritma ve Parametreler

Ajan, deneyimlerinden Ã¶ÄŸrenmek iÃ§in model-free bir algoritma olan Q-Learning'i kullanÄ±r. KeÅŸfetme ve sÃ¶mÃ¼rme (exploration vs. exploitation) dengesi, azalan epsilon (epsilon-decay) stratejisi ile saÄŸlanmÄ±ÅŸtÄ±r.

* **Ã–ÄŸrenme OranÄ± (Alpha - $\alpha$):** 0.1
* **Ä°ndirim FaktÃ¶rÃ¼ (Gamma - $\gamma$):** 0.99
* **BaÅŸlangÄ±Ã§ Epsilon DeÄŸeri:** 1.0
* **Epsilon Azalma OranÄ± (Decay):** 0.995

### ğŸ§® Q-Tablosu GÃ¼ncelleme KuralÄ±
Ajan, her adÄ±mda Q-deÄŸerlerini aÅŸaÄŸÄ±daki Bellman Denklemi temelli matematiksel formÃ¼le gÃ¶re gÃ¼nceller:

$$Q(s,a) \leftarrow Q(s,a) + \alpha [r + \gamma \max_{a'} Q(s',a') - Q(s,a)]$$

* $s$: Mevcut durum
* $a$: SeÃ§ilen eylem
* $r$: AlÄ±nan Ã¶dÃ¼l
* $s'$: Sonraki durum
* $\alpha$: Ã–ÄŸrenme oranÄ±
* $\gamma$: Ä°ndirim faktÃ¶rÃ¼

## ğŸ“ˆ SonuÃ§lar ve Ã–ÄŸrenme EÄŸrisi (Learning Curve)

Ajan ilk bÃ¶lÃ¼mlerde (episodes) ortamÄ± tamamen rastgele keÅŸfederken (exploration) ve sÄ±k sÄ±k engellere Ã§arparken, bÃ¶lÃ¼mler ilerledikÃ§e Q-tablosunu gÃ¼ncelleyerek hedefe giden optimal yolu Ã¶ÄŸrenmiÅŸtir (exploitation). 

AÅŸaÄŸÄ±daki grafik, ajanÄ±n eÄŸitim sÃ¼resi boyunca her bÃ¶lÃ¼mde topladÄ±ÄŸÄ± toplam Ã¶dÃ¼l miktarÄ±nÄ± gÃ¶stermektedir:

![Ã–ÄŸrenme EÄŸrisi](learning_curve.png) 

*(Not: Bu grafiÄŸi elde etmek iÃ§in `matplotlib` kÃ¼tÃ¼phanesi kullanÄ±lmÄ±ÅŸtÄ±r.)*

## ğŸš€ Kurulum ve KullanÄ±m

Projeyi kendi bilgisayarÄ±nda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyebilirsin:

1. Repoyu klonlayÄ±n:
   ```bash
   git clone [https://github.com/ferhattkoc-ml/robot-kesif-qlearning.git](https://github.com/ferhattkoc-ml/robot-kesif-qlearning.git)
